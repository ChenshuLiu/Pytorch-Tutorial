{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMseO7SfgnBuuFQgo3A9EXS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChenshuLiu/Pytorch-Tutorial/blob/main/Pytorch_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pytorch Tutorial\n",
        "#### Chenshu Liu\n",
        "Reference: https://youtu.be/c36lUUr864M?list=PLw1A_xmFf3RLPk5cKf1PZo6-3E-boYifg "
      ],
      "metadata": {
        "id": "1MCWWUfgt7-d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "IyTkiSd-wEaR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensors Basics\n",
        "* use `torch.empty(dimension)` to define an empty tensor object"
      ],
      "metadata": {
        "id": "G0mSU-Xwv8EK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZ0XKKHQtiIL",
        "outputId": "8c416c4c-eb1f-4ffd-a579-edbb635c6f37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[8.6337e-34, 0.0000e+00, 3.5032e-44],\n",
            "        [0.0000e+00,        nan, 0.0000e+00]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.empty(2, 3)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* use `torch.rand(dimension)` to define a tensor with random numbers with given dimension"
      ],
      "metadata": {
        "id": "f10af9QrwpZm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(2, 2)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSrUi-TwwQXk",
        "outputId": "6e02253a-d077-4479-ed1c-c284d6a92e2f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1364, 0.7621],\n",
            "        [0.7713, 0.0085]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* use `torch.ones(dimension, dtype)` to define tensor object with ones"
      ],
      "metadata": {
        "id": "XMSi5FDRxIzY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.ones(2, 2, dtype = torch.double)\n",
        "print(x)\n",
        "print(x.dtype)\n",
        "print(x.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xr_7MbLOw_86",
        "outputId": "220d7bd1-42a8-415d-cbf3-12e52c453c17"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]], dtype=torch.float64)\n",
            "torch.float64\n",
            "torch.Size([2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* use `torch.tensor([array of values])` to cast array of values into a tensor object"
      ],
      "metadata": {
        "id": "hzVCykIDxuba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([2.5, 0.1])\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFt2BRxWxQiw",
        "outputId": "38e26519-87c6-449e-9d2a-ba6bdbc05d81"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2.5000, 0.1000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensor Arithematics\n",
        "* Addition `torch.add(a,b)`\n",
        "* Subtraction `torch.sub(a,b)`\n",
        "* Multiplication `torch.mul(a,b)`\n",
        "* Division `torch.div(a,b)`\n",
        "* For in-place modification, add an underscore `_` behind the operation name (i.e. `a.add_(b)` will add a to b and assigned the sum to a)\n",
        "* Without `_` in the operation, the result need to be assigned to a new object (e.g. `c = a.add(b)`)"
      ],
      "metadata": {
        "id": "EuRP7NWdyNu2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(2, 2)\n",
        "y = torch.rand(2, 2)\n",
        "# elementwise addition\n",
        "z = x + y\n",
        "#  or\n",
        "z = torch.add(x, y)\n",
        "print(x)\n",
        "print(y)\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C230CKd6x7Uz",
        "outputId": "2c6ec444-2a66-44df-8f1f-992644c1bf1c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6109, 0.4688],\n",
            "        [0.5876, 0.3950]])\n",
            "tensor([[0.5343, 0.4071],\n",
            "        [0.7797, 0.0901]])\n",
            "tensor([[1.1452, 0.8760],\n",
            "        [1.3672, 0.4851]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = y.add(x)\n",
        "print(x)\n",
        "print(y)\n",
        "print(z)\n",
        "# in-place modification on y\n",
        "y.add_(x)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BH_14QCyeg2",
        "outputId": "fad027da-4cf6-4b52-c362-39b743c72342"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6109, 0.4688],\n",
            "        [0.5876, 0.3950]])\n",
            "tensor([[1.7561, 1.3448],\n",
            "        [1.9548, 0.8800]])\n",
            "tensor([[2.3670, 1.8137],\n",
            "        [2.5424, 1.2750]])\n",
            "tensor([[2.3670, 1.8137],\n",
            "        [2.5424, 1.2750]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensor Slicing"
      ],
      "metadata": {
        "id": "-6YH6WTjzkIG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(3, 3)\n",
        "print(x[1, 1])\n",
        "print(type(x[1, 1]))\n",
        "# extract only value from the position\n",
        "print(x[1, 1].item())\n",
        "print(type(x[1, 1].item()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pkk0vdwTy0Kx",
        "outputId": "0597acea-b266-4762-d979-1c7ed5ad83ad"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.9280)\n",
            "<class 'torch.Tensor'>\n",
            "0.9280080795288086\n",
            "<class 'float'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensor Resizing\n",
        "For unknown dimension, use `-1` and specify the other dimension (works the same in Numpy)"
      ],
      "metadata": {
        "id": "iGyl3oQ81M8w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(4, 4)\n",
        "print(x.shape)\n",
        "# -1 here is just a place-holder\n",
        "y = x.view((-1, 8))\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNaL5Bjg1Yga",
        "outputId": "7c2d27db-cefe-44f7-d05f-4ec3fa5e1d31"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 4])\n",
            "torch.Size([2, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensor and Numpy\n",
        "The `torch.from_numpy()` function converts numpy array to tensor object, but the change is made in-place (i.e. modifying the numpy array will also modify the converted tensor)"
      ],
      "metadata": {
        "id": "ZtppVs8JTYJU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.ones(5)\n",
        "b = torch.from_numpy(a)\n",
        "print(type(a))\n",
        "print(a)\n",
        "print(type(b))\n",
        "print(b)\n",
        "\n",
        "# modify numpy will also alter tensor\n",
        "a += 1\n",
        "print(a)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLAJFgvB138u",
        "outputId": "887dc1cd-6feb-4ac4-998d-a58f050a3eb4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "[1. 1. 1. 1. 1.]\n",
            "<class 'torch.Tensor'>\n",
            "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
            "[2. 2. 2. 2. 2.]\n",
            "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Autograd\n",
        "To calculate gradient for the model with respect to several values (i.e. $x_1, \\dots, x_n$) in preparation for the backward propagation, we use the `requires_grad = True` argument to keep track of the gradients.\n",
        "\n",
        "reference:\n",
        "1. Gradient: https://builtin.com/data-science/gradient-descent "
      ],
      "metadata": {
        "id": "q2ZdVWWgWbhN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "tVPOs-pf5rOe"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(3, requires_grad = True)\n",
        "print(x)\n",
        "\n",
        "y = x+2\n",
        "print(y) #backward gradient with addition -- \"AddBackward0\"\n",
        "z = y*y*2 \n",
        "print(z) #backward gradient with multiplication -- \"MulBackward0\"\n",
        "z = z.mean() \n",
        "print(z) #backward gradient with mean operation -- \"MeanBackward0\"\n",
        "z.backward()\n",
        "print(x.grad) #the gradients with respect to the three x's"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUuBE0ubToFd",
        "outputId": "10ef1a34-8032-427b-e319-d96ca6c54516"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-1.0523,  0.5415,  0.9816], requires_grad=True)\n",
            "tensor([0.9477, 2.5415, 2.9816], grad_fn=<AddBackward0>)\n",
            "tensor([ 1.7963, 12.9187, 17.7795], grad_fn=<MulBackward0>)\n",
            "tensor(10.8315, grad_fn=<MeanBackward0>)\n",
            "tensor([1.2636, 3.3887, 3.9754])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By default, `requires_grad` has a False argument, so when we try to request for gradient with respect to the independent variables (i.e. $x_1, \\dots, x_n$), there will be an error message."
      ],
      "metadata": {
        "id": "QwX346en5aZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(3, requires_grad = False)\n",
        "print(x)\n",
        "\n",
        "y = x+2\n",
        "print(y) #will not show backward gradient with addition -- \"AddBackward0\"\n",
        "z = y*y*2 \n",
        "print(z) #will not show backward gradient with multiplication -- \"MulBackward0\"\n",
        "z = z.mean() \n",
        "print(z) #will not show backward gradient with mean operation -- \"MeanBackward0\"\n",
        "z.backward() #will produce error because the gradients were not requested in x\n",
        "# print(x.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "id": "dkGcGokX3q8p",
        "outputId": "d1b280c0-56a4-4023-99ae-9ba726180f7a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.2098, -0.7104, -1.0785])\n",
            "tensor([1.7902, 1.2896, 0.9215])\n",
            "tensor([6.4095, 3.3259, 1.6985])\n",
            "tensor(3.8113)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-dbdb4638eb0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#will not show backward gradient with mean operation -- \"MeanBackward0\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#will produce error because the gradients were not requested in x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;31m# print(x.grad)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Removing Gradients Tracking\n",
        "Can remove the tracked gradients in the following ways:"
      ],
      "metadata": {
        "id": "V6rq4QMV7rtZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `tensorobj.requires_grad_(False)` (NOTE: any function with an underscore behind will modify the object in-place)"
      ],
      "metadata": {
        "id": "KAt0ToYp9z-d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(3, requires_grad = True)\n",
        "print(x)\n",
        "x.requires_grad_(False) #in-place modification\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6tl-cUn55wf",
        "outputId": "2fc03e40-1550-45a3-c0bb-fa414c430367"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.8699,  0.5317, -0.7827], requires_grad=True)\n",
            "tensor([ 0.8699,  0.5317, -0.7827])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `tensorobj.detach`"
      ],
      "metadata": {
        "id": "TE6oNgDl8RrC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(3, requires_grad = True)\n",
        "print(x)\n",
        "y = x.detach() #does not modify in-place\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLPDxhRh-BFb",
        "outputId": "6503cba2-2993-4609-a24c-21a07b0c108b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-1.0555,  0.7687,  0.2573], requires_grad=True)\n",
            "tensor([-1.0555,  0.7687,  0.2573])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Perform operations within a `with` statement: `with torch.no_grad(): blahblahblah`"
      ],
      "metadata": {
        "id": "fBITghEf8TBa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(3, requires_grad = True)\n",
        "print(x)\n",
        "with torch.no_grad():\n",
        "  y = x+2\n",
        "  print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rhrMNJ78SsQ",
        "outputId": "e5ede559-dbe5-4212-a58e-fe292546f2c0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.6684, -1.3532,  1.0301], requires_grad=True)\n",
            "tensor([2.6684, 0.6468, 3.0301])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gradients Accumulation During Epochs"
      ],
      "metadata": {
        "id": "SQjYx9Ne_mzV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torch.ones(4, requires_grad = True)\n",
        "\n",
        "for epoch in range(3):\n",
        "  model_output = (weights*3).sum()\n",
        "  model_output.backward()\n",
        "  print(weights.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPBdGRjA_rV1",
        "outputId": "581c3820-ca5a-40e1-8cce-97f7713dba45"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3., 3., 3., 3.])\n",
            "tensor([6., 6., 6., 6.])\n",
            "tensor([9., 9., 9., 9.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that in the three epochs, the gradients are accumulated. This is because the `backward` function will accumulate the gradients from the previous iteration. However, this is NOT what we want for model training (i.e. iterating through multiple epochs). Thus, we need to use the `grad.zero_()` function to modify the tracked gradients at the end of one epoch to restart the tracking."
      ],
      "metadata": {
        "id": "8KceKzES_-Nk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torch.ones(4, requires_grad = True)\n",
        "for epoch in range(3):\n",
        "  model_output = (weights*3).sum()\n",
        "  model_output.backward()\n",
        "  print(weights.grad)\n",
        "  weights.grad.zero_()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3b9_LWE0_9S9",
        "outputId": "8cfc1214-ca98-4b77-eb9e-8baedc9d18f1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, the gradients in every epoch seems right (i.e. we shouldn't expect any change in the gradients because the model stayed the same)"
      ],
      "metadata": {
        "id": "V900fWP6A6Tj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Backpropagation"
      ],
      "metadata": {
        "id": "cyrU4n-uBtiQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ILNVCC_AA4bY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}